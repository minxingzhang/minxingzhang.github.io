---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
redirect_from:
  - /resume
---

<style type="text/css" rel="stylesheet">
.btn--paper {
color: white;
background-color: lightseagreen;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
.btn--arxiv {
color: white;
background-color: tan;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
.btn--code {
color: white;
background-color: DARKORANGE;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
.btn--award {
color: white;
background-color: TOMATO;
padding: 1px 3px;
text-align: center;
border-radius: 4px;
a { TEXT-DECORATION:none }
}
</style>

(**Bold** for me, <sup>*</sup> for equal contribution)

-------------------------------------

> *2025*

### *DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy*

Wenshu Fan<sup>*</sup>, **Minxing Zhang**<sup>*</sup>, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Xiangyu Yue, Michael Backes, Xiao Zhang

ACM CCS, 2025
<a href="https://arxiv.org/pdf/2501.06533" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2501.06533" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/fiora6/divtrackee" class="btn--code" target="_blank">code</a>

<a href="https://www.sigsac.org/ccs/CCS2025/awards/" class="btn--award" target="_blank">Distinguished Paper Award</a>

### *Generating Less Certain Adversarial Examples Improves Robust Generalization*

**Minxing Zhang**, Michael Backes, Xiao Zhang

ICLR, 2025
<a href="https://arxiv.org/pdf/2310.04539" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2310.04539" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/TrustMLRG/AdvCertainty" class="btn--code" target="_blank">code</a>

<!--
(Invited to __ICLR__ 2025 for presentation as a <a href="https://iclr.cc/virtual/2025/poster/31455" target="_blank">poster</a>.)
-->

### *Invisibility Cloak: Disappearance under Human Pose Estimation via Backdoor Attacks*

**Minxing Zhang**, Michael Backes, Xiao Zhang

arXiv
<a href="https://arxiv.org/pdf/2410.07670" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2410.07670" class="btn--arxiv" target="_blank">arxiv</a>

> *2024*

### *Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models*

**Minxing Zhang**, Ning Yu, Rui Wen, Michael Backes, Yang Zhang

IEEE/CVF WACV, 2024
<a href="https://arxiv.org/pdf/2310.19410" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2310.19410" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/minxingzhang/MIAGM" class="btn--code" target="_blank">code</a>

### *Generating Less Certain Adversarial Examples Improves Robust Generalization*

**Minxing Zhang**, Michael Backes, Xiao Zhang

TMLR, 2024
<a href="https://arxiv.org/pdf/2310.04539" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2310.04539" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/TrustMLRG/AdvCertainty" class="btn--code" target="_blank">code</a>

### *Vera Verto: Multimodal Hijacking Attack*

**Minxing Zhang**, Ahmed Salem, Michael Backes, Yang Zhang

arXiv
<a href="https://arxiv.org/pdf/2408.00129" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2408.00129" class="btn--arxiv" target="_blank">arxiv</a>

> *2021*

### *Membership Inference Attacks Against Recommender Systems*

**Minxing Zhang**, Zhaochun Ren, Zihan Wang, Pengjie Ren, Zhunmin Chen, Pengfei Hu, Yang Zhang

ACM CCS, 2021
<a href="https://arxiv.org/pdf/2109.08045" class="btn--paper" target="_blank">pdf</a>
<a href="https://arxiv.org/abs/2109.08045" class="btn--arxiv" target="_blank">arxiv</a>
<a href="https://github.com/minxingzhang/MIARS" class="btn--code" target="_blank">code</a>
